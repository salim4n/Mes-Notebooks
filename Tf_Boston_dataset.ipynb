{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYVoskASoPWNqWWLHs73nP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salim4n/kaggle_competition/blob/main/Tf_Boston_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TMzuAODzoDSQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "target = raw_df.values[1::2, 2]\n",
        "data = data\n",
        "target = target\n",
        "\n",
        "X = data\n",
        "Y = target.reshape((506, 1))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=0)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "metadata": {
        "id": "bNj0rbKToNVp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([Dense(units=13, activation='sigmoid'),\n",
        "                    Dense(units=8, activation='sigmoid'),\n",
        "                    Dense(units=5, activation='sigmoid'),\n",
        "                    Dense(units=1)\n",
        "                    ])\n",
        "\n",
        "model.compile(loss=\"mse\",optimizer=SGD(learning_rate=0.001))\n",
        "h = model.fit(X_train, y_train, epochs=500, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhvmqOgOo5mC",
        "outputId": "941ffac1-bf68-4abe-f239-b65a42005c60"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 14ms/step - loss: 568.3067 - val_loss: 522.2194\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 513.7930 - val_loss: 467.5239\n",
            "Epoch 3/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 457.0591 - val_loss: 410.5306\n",
            "Epoch 4/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 399.3129 - val_loss: 354.6924\n",
            "Epoch 5/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 344.8065 - val_loss: 304.4841\n",
            "Epoch 6/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 297.0103 - val_loss: 261.6436\n",
            "Epoch 7/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 256.6630 - val_loss: 226.2749\n",
            "Epoch 8/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 223.3746 - val_loss: 197.0397\n",
            "Epoch 9/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 195.8681 - val_loss: 173.0776\n",
            "Epoch 10/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 173.3413 - val_loss: 153.7613\n",
            "Epoch 11/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 155.1709 - val_loss: 138.1792\n",
            "Epoch 12/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 140.5361 - val_loss: 125.8587\n",
            "Epoch 13/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 128.8806 - val_loss: 116.0408\n",
            "Epoch 14/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 119.5897 - val_loss: 108.3327\n",
            "Epoch 15/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 112.2597 - val_loss: 102.2709\n",
            "Epoch 16/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 106.4505 - val_loss: 97.5714\n",
            "Epoch 17/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 101.9332 - val_loss: 93.9209\n",
            "Epoch 18/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 98.3456 - val_loss: 91.0914\n",
            "Epoch 19/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 95.5629 - val_loss: 88.8724\n",
            "Epoch 20/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 93.3606 - val_loss: 87.1628\n",
            "Epoch 21/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 91.6274 - val_loss: 85.8269\n",
            "Epoch 22/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 90.2499 - val_loss: 84.7783\n",
            "Epoch 23/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 89.1469 - val_loss: 83.9979\n",
            "Epoch 24/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 88.3107 - val_loss: 83.4042\n",
            "Epoch 25/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 87.6640 - val_loss: 82.9369\n",
            "Epoch 26/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 87.1399 - val_loss: 82.5782\n",
            "Epoch 27/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 86.7164 - val_loss: 82.3045\n",
            "Epoch 28/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 86.3859 - val_loss: 82.0912\n",
            "Epoch 29/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 86.1164 - val_loss: 81.9281\n",
            "Epoch 30/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 85.9029 - val_loss: 81.8036\n",
            "Epoch 31/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 85.7316 - val_loss: 81.7132\n",
            "Epoch 32/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 85.5754 - val_loss: 81.6415\n",
            "Epoch 33/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 85.4825 - val_loss: 81.5881\n",
            "Epoch 34/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 85.3715 - val_loss: 81.5487\n",
            "Epoch 35/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 85.2918 - val_loss: 81.5178\n",
            "Epoch 36/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 85.2419 - val_loss: 81.4912\n",
            "Epoch 37/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 85.1749 - val_loss: 81.4694\n",
            "Epoch 38/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 85.1176 - val_loss: 81.4503\n",
            "Epoch 39/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 85.0805 - val_loss: 81.4330\n",
            "Epoch 40/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 85.0366 - val_loss: 81.4173\n",
            "Epoch 41/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 85.0147 - val_loss: 81.4018\n",
            "Epoch 42/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 84.9532 - val_loss: 81.3839\n",
            "Epoch 43/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 84.9272 - val_loss: 81.3680\n",
            "Epoch 44/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 84.8883 - val_loss: 81.3496\n",
            "Epoch 45/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 84.8710 - val_loss: 81.3287\n",
            "Epoch 46/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 84.8350 - val_loss: 81.3069\n",
            "Epoch 47/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 84.7851 - val_loss: 81.2861\n",
            "Epoch 48/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 84.7621 - val_loss: 81.2606\n",
            "Epoch 49/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 84.7177 - val_loss: 81.2391\n",
            "Epoch 50/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 84.6748 - val_loss: 81.2125\n",
            "Epoch 51/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 84.6659 - val_loss: 81.1882\n",
            "Epoch 52/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 84.5964 - val_loss: 81.1569\n",
            "Epoch 53/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 84.5599 - val_loss: 81.1217\n",
            "Epoch 54/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 84.4905 - val_loss: 81.0877\n",
            "Epoch 55/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 84.4614 - val_loss: 81.0452\n",
            "Epoch 56/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 84.3880 - val_loss: 81.0047\n",
            "Epoch 57/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 84.3616 - val_loss: 80.9679\n",
            "Epoch 58/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 84.3088 - val_loss: 80.9191\n",
            "Epoch 59/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 84.2159 - val_loss: 80.8699\n",
            "Epoch 60/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 84.1456 - val_loss: 80.8171\n",
            "Epoch 61/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 84.0933 - val_loss: 80.7629\n",
            "Epoch 62/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 84.0254 - val_loss: 80.7021\n",
            "Epoch 63/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 83.9169 - val_loss: 80.6369\n",
            "Epoch 64/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 83.8374 - val_loss: 80.5674\n",
            "Epoch 65/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 83.7653 - val_loss: 80.4966\n",
            "Epoch 66/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 83.6674 - val_loss: 80.4176\n",
            "Epoch 67/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 83.5572 - val_loss: 80.3270\n",
            "Epoch 68/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 83.4308 - val_loss: 80.2289\n",
            "Epoch 69/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 83.2884 - val_loss: 80.1293\n",
            "Epoch 70/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 83.1555 - val_loss: 80.0178\n",
            "Epoch 71/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 82.9988 - val_loss: 79.8957\n",
            "Epoch 72/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 82.8515 - val_loss: 79.7677\n",
            "Epoch 73/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 82.6588 - val_loss: 79.6195\n",
            "Epoch 74/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 82.4658 - val_loss: 79.4578\n",
            "Epoch 75/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 82.3002 - val_loss: 79.2886\n",
            "Epoch 76/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 82.0383 - val_loss: 79.1039\n",
            "Epoch 77/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 81.7743 - val_loss: 78.8934\n",
            "Epoch 78/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 81.4892 - val_loss: 78.6675\n",
            "Epoch 79/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 81.1614 - val_loss: 78.4186\n",
            "Epoch 80/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 80.8652 - val_loss: 78.1610\n",
            "Epoch 81/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 80.4572 - val_loss: 77.8625\n",
            "Epoch 82/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 80.0354 - val_loss: 77.5370\n",
            "Epoch 83/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 79.5773 - val_loss: 77.1786\n",
            "Epoch 84/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 79.0674 - val_loss: 76.7885\n",
            "Epoch 85/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 78.5291 - val_loss: 76.3746\n",
            "Epoch 86/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 77.9145 - val_loss: 75.9366\n",
            "Epoch 87/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 77.2738 - val_loss: 75.4675\n",
            "Epoch 88/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 76.5793 - val_loss: 74.9773\n",
            "Epoch 89/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 75.8612 - val_loss: 74.4683\n",
            "Epoch 90/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 75.0900 - val_loss: 73.9508\n",
            "Epoch 91/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 74.2958 - val_loss: 73.4251\n",
            "Epoch 92/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 73.4927 - val_loss: 72.8898\n",
            "Epoch 93/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 72.6722 - val_loss: 72.3565\n",
            "Epoch 94/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 71.8097 - val_loss: 71.8215\n",
            "Epoch 95/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 70.9632 - val_loss: 71.2893\n",
            "Epoch 96/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 70.1066 - val_loss: 70.7518\n",
            "Epoch 97/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 69.2450 - val_loss: 70.2203\n",
            "Epoch 98/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 68.3792 - val_loss: 69.6917\n",
            "Epoch 99/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 67.4757 - val_loss: 69.1702\n",
            "Epoch 100/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 66.6144 - val_loss: 68.6476\n",
            "Epoch 101/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 65.7276 - val_loss: 68.1280\n",
            "Epoch 102/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 64.8331 - val_loss: 67.6104\n",
            "Epoch 103/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 63.9503 - val_loss: 67.0973\n",
            "Epoch 104/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 63.0807 - val_loss: 66.5831\n",
            "Epoch 105/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 62.1893 - val_loss: 66.0760\n",
            "Epoch 106/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 61.3067 - val_loss: 65.5742\n",
            "Epoch 107/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 60.4249 - val_loss: 65.0782\n",
            "Epoch 108/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 59.5439 - val_loss: 64.5862\n",
            "Epoch 109/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 58.6648 - val_loss: 64.1031\n",
            "Epoch 110/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 57.8090 - val_loss: 63.6245\n",
            "Epoch 111/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 56.9302 - val_loss: 63.1533\n",
            "Epoch 112/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 56.0821 - val_loss: 62.6857\n",
            "Epoch 113/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 55.2379 - val_loss: 62.2276\n",
            "Epoch 114/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 54.4085 - val_loss: 61.7708\n",
            "Epoch 115/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 53.6092 - val_loss: 61.3247\n",
            "Epoch 116/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 52.8453 - val_loss: 60.8817\n",
            "Epoch 117/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 52.0230 - val_loss: 60.4392\n",
            "Epoch 118/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 51.2894 - val_loss: 60.0063\n",
            "Epoch 119/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 50.4867 - val_loss: 59.5725\n",
            "Epoch 120/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 49.7497 - val_loss: 59.1337\n",
            "Epoch 121/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 49.0141 - val_loss: 58.6952\n",
            "Epoch 122/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 48.3029 - val_loss: 58.2561\n",
            "Epoch 123/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 47.5945 - val_loss: 57.8122\n",
            "Epoch 124/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 46.9166 - val_loss: 57.3614\n",
            "Epoch 125/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 46.2458 - val_loss: 56.9017\n",
            "Epoch 126/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 45.5866 - val_loss: 56.4446\n",
            "Epoch 127/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 44.9535 - val_loss: 55.9638\n",
            "Epoch 128/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 44.3151 - val_loss: 55.4796\n",
            "Epoch 129/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 43.6804 - val_loss: 54.9710\n",
            "Epoch 130/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 43.0769 - val_loss: 54.4697\n",
            "Epoch 131/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 42.4632 - val_loss: 53.9574\n",
            "Epoch 132/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 41.8552 - val_loss: 53.4270\n",
            "Epoch 133/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 41.2815 - val_loss: 52.8882\n",
            "Epoch 134/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 40.6984 - val_loss: 52.3464\n",
            "Epoch 135/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 40.1247 - val_loss: 51.7886\n",
            "Epoch 136/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 39.5373 - val_loss: 51.2365\n",
            "Epoch 137/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 38.9939 - val_loss: 50.6864\n",
            "Epoch 138/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 38.4323 - val_loss: 50.1194\n",
            "Epoch 139/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 37.9060 - val_loss: 49.5704\n",
            "Epoch 140/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 37.3549 - val_loss: 49.0423\n",
            "Epoch 141/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 36.8611 - val_loss: 48.5162\n",
            "Epoch 142/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 36.3659 - val_loss: 47.9775\n",
            "Epoch 143/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 35.8597 - val_loss: 47.4529\n",
            "Epoch 144/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 35.3882 - val_loss: 46.9257\n",
            "Epoch 145/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 34.9280 - val_loss: 46.4606\n",
            "Epoch 146/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 34.5089 - val_loss: 45.9808\n",
            "Epoch 147/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 34.0498 - val_loss: 45.5376\n",
            "Epoch 148/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 33.6541 - val_loss: 45.1296\n",
            "Epoch 149/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 33.2414 - val_loss: 44.7600\n",
            "Epoch 150/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 32.8987 - val_loss: 44.3614\n",
            "Epoch 151/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 32.5065 - val_loss: 43.9659\n",
            "Epoch 152/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 32.1611 - val_loss: 43.6512\n",
            "Epoch 153/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 31.8308 - val_loss: 43.3298\n",
            "Epoch 154/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 31.4821 - val_loss: 43.0540\n",
            "Epoch 155/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 31.1652 - val_loss: 42.7793\n",
            "Epoch 156/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 30.8662 - val_loss: 42.4818\n",
            "Epoch 157/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 30.5625 - val_loss: 42.1804\n",
            "Epoch 158/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 30.2727 - val_loss: 41.9150\n",
            "Epoch 159/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 29.9733 - val_loss: 41.6213\n",
            "Epoch 160/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 29.7361 - val_loss: 41.4182\n",
            "Epoch 161/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 29.5024 - val_loss: 41.1657\n",
            "Epoch 162/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 29.2051 - val_loss: 40.9298\n",
            "Epoch 163/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 28.9764 - val_loss: 40.6541\n",
            "Epoch 164/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 28.7049 - val_loss: 40.4299\n",
            "Epoch 165/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 28.4887 - val_loss: 40.2230\n",
            "Epoch 166/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 28.2418 - val_loss: 40.0691\n",
            "Epoch 167/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 28.0410 - val_loss: 39.8675\n",
            "Epoch 168/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 27.8230 - val_loss: 39.6381\n",
            "Epoch 169/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 27.6168 - val_loss: 39.4729\n",
            "Epoch 170/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 27.4126 - val_loss: 39.2599\n",
            "Epoch 171/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 27.2155 - val_loss: 39.1029\n",
            "Epoch 172/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 27.0321 - val_loss: 38.8998\n",
            "Epoch 173/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 26.8148 - val_loss: 38.6517\n",
            "Epoch 174/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 26.6245 - val_loss: 38.5088\n",
            "Epoch 175/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 26.4392 - val_loss: 38.2756\n",
            "Epoch 176/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 26.2588 - val_loss: 38.1318\n",
            "Epoch 177/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 26.0911 - val_loss: 37.9510\n",
            "Epoch 178/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 25.9182 - val_loss: 37.8063\n",
            "Epoch 179/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25.7252 - val_loss: 37.6470\n",
            "Epoch 180/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25.5731 - val_loss: 37.4397\n",
            "Epoch 181/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 25.4142 - val_loss: 37.3704\n",
            "Epoch 182/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25.2458 - val_loss: 37.1236\n",
            "Epoch 183/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25.0704 - val_loss: 36.9405\n",
            "Epoch 184/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24.9127 - val_loss: 36.7846\n",
            "Epoch 185/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 24.7633 - val_loss: 36.6231\n",
            "Epoch 186/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24.6094 - val_loss: 36.5127\n",
            "Epoch 187/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 24.4999 - val_loss: 36.1950\n",
            "Epoch 188/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 24.3459 - val_loss: 36.0397\n",
            "Epoch 189/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24.1716 - val_loss: 35.8539\n",
            "Epoch 190/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24.0077 - val_loss: 35.7327\n",
            "Epoch 191/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 23.8660 - val_loss: 35.6711\n",
            "Epoch 192/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23.7568 - val_loss: 35.5210\n",
            "Epoch 193/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 23.6182 - val_loss: 35.2605\n",
            "Epoch 194/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 23.4621 - val_loss: 35.1330\n",
            "Epoch 195/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 23.3372 - val_loss: 34.9808\n",
            "Epoch 196/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23.1944 - val_loss: 34.8084\n",
            "Epoch 197/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 23.0585 - val_loss: 34.7587\n",
            "Epoch 198/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 22.9232 - val_loss: 34.6980\n",
            "Epoch 199/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 22.8117 - val_loss: 34.5299\n",
            "Epoch 200/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 22.6727 - val_loss: 34.3500\n",
            "Epoch 201/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 22.5189 - val_loss: 34.2333\n",
            "Epoch 202/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 22.4002 - val_loss: 34.2055\n",
            "Epoch 203/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 22.2732 - val_loss: 34.1134\n",
            "Epoch 204/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 22.1593 - val_loss: 33.9240\n",
            "Epoch 205/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 22.0554 - val_loss: 33.7388\n",
            "Epoch 206/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 21.9177 - val_loss: 33.5640\n",
            "Epoch 207/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 21.7794 - val_loss: 33.4019\n",
            "Epoch 208/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 21.6852 - val_loss: 33.3866\n",
            "Epoch 209/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 21.5619 - val_loss: 33.2573\n",
            "Epoch 210/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 21.4494 - val_loss: 33.1197\n",
            "Epoch 211/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 21.3590 - val_loss: 32.9075\n",
            "Epoch 212/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 21.2268 - val_loss: 32.7649\n",
            "Epoch 213/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 21.1306 - val_loss: 32.6384\n",
            "Epoch 214/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 20.9930 - val_loss: 32.4534\n",
            "Epoch 215/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 20.9374 - val_loss: 32.5053\n",
            "Epoch 216/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 20.7785 - val_loss: 32.4118\n",
            "Epoch 217/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 20.6914 - val_loss: 32.4066\n",
            "Epoch 218/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 20.6261 - val_loss: 32.1406\n",
            "Epoch 219/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 20.4654 - val_loss: 31.9848\n",
            "Epoch 220/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 20.3561 - val_loss: 31.9910\n",
            "Epoch 221/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 20.2592 - val_loss: 31.8757\n",
            "Epoch 222/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 20.1611 - val_loss: 31.7924\n",
            "Epoch 223/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 20.0594 - val_loss: 31.6483\n",
            "Epoch 224/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 19.9488 - val_loss: 31.5576\n",
            "Epoch 225/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 19.8476 - val_loss: 31.4206\n",
            "Epoch 226/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 19.7684 - val_loss: 31.3080\n",
            "Epoch 227/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 19.6378 - val_loss: 31.0593\n",
            "Epoch 228/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 19.5601 - val_loss: 31.0918\n",
            "Epoch 229/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 19.4856 - val_loss: 31.0352\n",
            "Epoch 230/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 19.3619 - val_loss: 30.9765\n",
            "Epoch 231/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 19.2647 - val_loss: 30.9437\n",
            "Epoch 232/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 19.2137 - val_loss: 30.8361\n",
            "Epoch 233/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 19.0570 - val_loss: 30.6138\n",
            "Epoch 234/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 19.0239 - val_loss: 30.5574\n",
            "Epoch 235/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 18.9387 - val_loss: 30.5350\n",
            "Epoch 236/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 18.8058 - val_loss: 30.3556\n",
            "Epoch 237/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 18.7381 - val_loss: 30.3407\n",
            "Epoch 238/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 18.6243 - val_loss: 30.3401\n",
            "Epoch 239/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 18.5819 - val_loss: 30.2208\n",
            "Epoch 240/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 18.4841 - val_loss: 30.1377\n",
            "Epoch 241/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 18.3944 - val_loss: 29.8945\n",
            "Epoch 242/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 18.3266 - val_loss: 29.8881\n",
            "Epoch 243/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 18.2131 - val_loss: 29.7848\n",
            "Epoch 244/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 18.1219 - val_loss: 29.6129\n",
            "Epoch 245/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 18.0576 - val_loss: 29.6843\n",
            "Epoch 246/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 17.9897 - val_loss: 29.7634\n",
            "Epoch 247/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 17.9237 - val_loss: 29.6806\n",
            "Epoch 248/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 17.8509 - val_loss: 29.4204\n",
            "Epoch 249/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 17.7339 - val_loss: 29.2622\n",
            "Epoch 250/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 17.6981 - val_loss: 29.2187\n",
            "Epoch 251/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 17.5760 - val_loss: 28.8209\n",
            "Epoch 252/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 17.5168 - val_loss: 28.9030\n",
            "Epoch 253/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 17.4012 - val_loss: 28.9435\n",
            "Epoch 254/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 17.3345 - val_loss: 28.8866\n",
            "Epoch 255/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 17.2702 - val_loss: 29.0958\n",
            "Epoch 256/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 17.2217 - val_loss: 28.9144\n",
            "Epoch 257/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 17.0991 - val_loss: 28.8302\n",
            "Epoch 258/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 17.0757 - val_loss: 28.8080\n",
            "Epoch 259/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 17.0042 - val_loss: 28.6371\n",
            "Epoch 260/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 16.9386 - val_loss: 28.4757\n",
            "Epoch 261/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 16.8510 - val_loss: 28.4833\n",
            "Epoch 262/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 16.7979 - val_loss: 28.3635\n",
            "Epoch 263/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 16.7010 - val_loss: 28.1003\n",
            "Epoch 264/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 16.6320 - val_loss: 28.2619\n",
            "Epoch 265/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 16.5454 - val_loss: 28.2411\n",
            "Epoch 266/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 16.5271 - val_loss: 28.1133\n",
            "Epoch 267/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 16.4356 - val_loss: 28.0973\n",
            "Epoch 268/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 16.3488 - val_loss: 27.8026\n",
            "Epoch 269/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 16.2963 - val_loss: 27.9381\n",
            "Epoch 270/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 16.2186 - val_loss: 27.8316\n",
            "Epoch 271/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 16.2168 - val_loss: 27.6871\n",
            "Epoch 272/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 16.0686 - val_loss: 27.5435\n",
            "Epoch 273/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 16.0071 - val_loss: 27.6165\n",
            "Epoch 274/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 15.9363 - val_loss: 27.6217\n",
            "Epoch 275/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 15.8839 - val_loss: 27.5749\n",
            "Epoch 276/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 15.8257 - val_loss: 27.3767\n",
            "Epoch 277/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 15.8139 - val_loss: 27.4067\n",
            "Epoch 278/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 15.6946 - val_loss: 27.4691\n",
            "Epoch 279/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 15.6171 - val_loss: 27.3696\n",
            "Epoch 280/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 15.5674 - val_loss: 27.2229\n",
            "Epoch 281/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 15.4747 - val_loss: 27.4330\n",
            "Epoch 282/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 15.4555 - val_loss: 27.4170\n",
            "Epoch 283/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 15.3829 - val_loss: 27.5296\n",
            "Epoch 284/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 15.3510 - val_loss: 27.3772\n",
            "Epoch 285/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 15.3266 - val_loss: 27.4258\n",
            "Epoch 286/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 15.2398 - val_loss: 27.3627\n",
            "Epoch 287/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 15.1594 - val_loss: 27.1360\n",
            "Epoch 288/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 15.1085 - val_loss: 27.0030\n",
            "Epoch 289/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 15.0167 - val_loss: 26.8724\n",
            "Epoch 290/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 14.9532 - val_loss: 26.8227\n",
            "Epoch 291/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 14.9205 - val_loss: 26.9089\n",
            "Epoch 292/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 14.9170 - val_loss: 26.8419\n",
            "Epoch 293/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 14.8062 - val_loss: 26.9105\n",
            "Epoch 294/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 14.7085 - val_loss: 26.6669\n",
            "Epoch 295/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 14.6971 - val_loss: 26.5931\n",
            "Epoch 296/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 14.6059 - val_loss: 26.7053\n",
            "Epoch 297/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 14.6000 - val_loss: 26.3167\n",
            "Epoch 298/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 14.5014 - val_loss: 26.4936\n",
            "Epoch 299/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 14.4827 - val_loss: 26.3909\n",
            "Epoch 300/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 14.4321 - val_loss: 26.1992\n",
            "Epoch 301/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 14.3404 - val_loss: 26.2766\n",
            "Epoch 302/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 14.3045 - val_loss: 26.1085\n",
            "Epoch 303/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 14.2428 - val_loss: 26.2408\n",
            "Epoch 304/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 14.1936 - val_loss: 26.1439\n",
            "Epoch 305/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 14.1434 - val_loss: 26.1488\n",
            "Epoch 306/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 14.0444 - val_loss: 26.3395\n",
            "Epoch 307/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 14.0288 - val_loss: 26.1374\n",
            "Epoch 308/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 13.9732 - val_loss: 26.1598\n",
            "Epoch 309/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 13.9203 - val_loss: 26.1924\n",
            "Epoch 310/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 13.8673 - val_loss: 26.0069\n",
            "Epoch 311/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 13.8251 - val_loss: 26.0044\n",
            "Epoch 312/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 13.7519 - val_loss: 25.8532\n",
            "Epoch 313/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 13.7262 - val_loss: 25.9571\n",
            "Epoch 314/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 13.6444 - val_loss: 25.9382\n",
            "Epoch 315/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 13.6290 - val_loss: 25.8239\n",
            "Epoch 316/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 13.5805 - val_loss: 25.8747\n",
            "Epoch 317/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 13.5340 - val_loss: 25.9358\n",
            "Epoch 318/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 13.4976 - val_loss: 25.6931\n",
            "Epoch 319/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 13.4183 - val_loss: 25.2686\n",
            "Epoch 320/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 13.4580 - val_loss: 25.6690\n",
            "Epoch 321/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 13.2988 - val_loss: 25.6514\n",
            "Epoch 322/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 13.2621 - val_loss: 25.2273\n",
            "Epoch 323/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 13.2136 - val_loss: 25.5634\n",
            "Epoch 324/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 13.1910 - val_loss: 25.3687\n",
            "Epoch 325/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 13.1222 - val_loss: 25.6142\n",
            "Epoch 326/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 13.1205 - val_loss: 25.5644\n",
            "Epoch 327/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 13.0463 - val_loss: 25.2529\n",
            "Epoch 328/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 12.9956 - val_loss: 25.0487\n",
            "Epoch 329/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.9634 - val_loss: 25.1925\n",
            "Epoch 330/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 12.9190 - val_loss: 24.9641\n",
            "Epoch 331/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.8724 - val_loss: 25.0940\n",
            "Epoch 332/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 12.8155 - val_loss: 24.9962\n",
            "Epoch 333/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 12.7245 - val_loss: 25.0615\n",
            "Epoch 334/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.7012 - val_loss: 24.8921\n",
            "Epoch 335/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.6399 - val_loss: 24.8713\n",
            "Epoch 336/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.6209 - val_loss: 24.9667\n",
            "Epoch 337/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 12.5904 - val_loss: 24.6944\n",
            "Epoch 338/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 12.5482 - val_loss: 24.7303\n",
            "Epoch 339/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 12.5232 - val_loss: 24.8469\n",
            "Epoch 340/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.4322 - val_loss: 24.9024\n",
            "Epoch 341/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.4325 - val_loss: 24.6255\n",
            "Epoch 342/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 12.3464 - val_loss: 24.6274\n",
            "Epoch 343/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.3036 - val_loss: 24.9643\n",
            "Epoch 344/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 12.2944 - val_loss: 24.5735\n",
            "Epoch 345/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 12.2255 - val_loss: 24.8258\n",
            "Epoch 346/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.1858 - val_loss: 24.9138\n",
            "Epoch 347/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.1730 - val_loss: 24.9862\n",
            "Epoch 348/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.0765 - val_loss: 24.6035\n",
            "Epoch 349/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 12.0599 - val_loss: 24.2395\n",
            "Epoch 350/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 12.0329 - val_loss: 24.2512\n",
            "Epoch 351/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 11.9791 - val_loss: 24.3242\n",
            "Epoch 352/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 12.0009 - val_loss: 24.5256\n",
            "Epoch 353/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.9083 - val_loss: 24.6429\n",
            "Epoch 354/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 11.8599 - val_loss: 24.4286\n",
            "Epoch 355/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.8357 - val_loss: 24.2186\n",
            "Epoch 356/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 11.7957 - val_loss: 24.3890\n",
            "Epoch 357/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.6907 - val_loss: 24.3951\n",
            "Epoch 358/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 11.6850 - val_loss: 24.2832\n",
            "Epoch 359/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.6875 - val_loss: 23.9913\n",
            "Epoch 360/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.6283 - val_loss: 24.1256\n",
            "Epoch 361/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11.6077 - val_loss: 23.9221\n",
            "Epoch 362/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.5129 - val_loss: 23.9790\n",
            "Epoch 363/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.4892 - val_loss: 24.1938\n",
            "Epoch 364/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.4558 - val_loss: 23.9855\n",
            "Epoch 365/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.3945 - val_loss: 23.8138\n",
            "Epoch 366/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.4049 - val_loss: 23.8643\n",
            "Epoch 367/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11.3456 - val_loss: 24.0602\n",
            "Epoch 368/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.3268 - val_loss: 23.9063\n",
            "Epoch 369/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 11.2793 - val_loss: 23.8774\n",
            "Epoch 370/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11.2258 - val_loss: 23.7459\n",
            "Epoch 371/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11.1770 - val_loss: 23.8470\n",
            "Epoch 372/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 11.2013 - val_loss: 23.8219\n",
            "Epoch 373/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11.0921 - val_loss: 23.7591\n",
            "Epoch 374/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 11.0540 - val_loss: 23.6530\n",
            "Epoch 375/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.0582 - val_loss: 23.4690\n",
            "Epoch 376/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.9946 - val_loss: 23.4822\n",
            "Epoch 377/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10.9410 - val_loss: 23.2168\n",
            "Epoch 378/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.9292 - val_loss: 23.4540\n",
            "Epoch 379/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10.9276 - val_loss: 23.6621\n",
            "Epoch 380/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10.9255 - val_loss: 23.4665\n",
            "Epoch 381/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10.8537 - val_loss: 23.2517\n",
            "Epoch 382/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10.8086 - val_loss: 23.4858\n",
            "Epoch 383/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10.7677 - val_loss: 23.3017\n",
            "Epoch 384/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10.7160 - val_loss: 23.4495\n",
            "Epoch 385/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 10.6762 - val_loss: 23.5642\n",
            "Epoch 386/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.6922 - val_loss: 23.2201\n",
            "Epoch 387/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.6245 - val_loss: 23.4340\n",
            "Epoch 388/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10.5715 - val_loss: 23.0311\n",
            "Epoch 389/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.6834 - val_loss: 22.9949\n",
            "Epoch 390/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.5390 - val_loss: 23.0493\n",
            "Epoch 391/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10.5240 - val_loss: 23.2752\n",
            "Epoch 392/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.4640 - val_loss: 23.2465\n",
            "Epoch 393/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.4508 - val_loss: 23.1760\n",
            "Epoch 394/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.3813 - val_loss: 22.7276\n",
            "Epoch 395/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10.3952 - val_loss: 22.4552\n",
            "Epoch 396/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.3437 - val_loss: 22.6875\n",
            "Epoch 397/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.2851 - val_loss: 22.9192\n",
            "Epoch 398/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.3132 - val_loss: 22.4743\n",
            "Epoch 399/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.2225 - val_loss: 22.7722\n",
            "Epoch 400/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10.2082 - val_loss: 22.5675\n",
            "Epoch 401/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.2257 - val_loss: 22.1845\n",
            "Epoch 402/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.1821 - val_loss: 22.6295\n",
            "Epoch 403/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.1099 - val_loss: 23.0013\n",
            "Epoch 404/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.0937 - val_loss: 22.4864\n",
            "Epoch 405/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.0626 - val_loss: 22.3818\n",
            "Epoch 406/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10.0500 - val_loss: 22.8286\n",
            "Epoch 407/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.9873 - val_loss: 22.3399\n",
            "Epoch 408/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 9.9574 - val_loss: 22.5954\n",
            "Epoch 409/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.9303 - val_loss: 22.5620\n",
            "Epoch 410/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9.9061 - val_loss: 22.2178\n",
            "Epoch 411/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9.8633 - val_loss: 22.1974\n",
            "Epoch 412/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.8386 - val_loss: 21.9902\n",
            "Epoch 413/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9.8145 - val_loss: 22.0286\n",
            "Epoch 414/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.8608 - val_loss: 22.0782\n",
            "Epoch 415/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.7546 - val_loss: 22.2312\n",
            "Epoch 416/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.6746 - val_loss: 22.0720\n",
            "Epoch 417/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.7216 - val_loss: 22.3669\n",
            "Epoch 418/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.7573 - val_loss: 22.1644\n",
            "Epoch 419/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9.6657 - val_loss: 21.8755\n",
            "Epoch 420/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.6685 - val_loss: 21.8237\n",
            "Epoch 421/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.6060 - val_loss: 21.7653\n",
            "Epoch 422/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.6241 - val_loss: 22.0288\n",
            "Epoch 423/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.5727 - val_loss: 21.9229\n",
            "Epoch 424/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.5591 - val_loss: 22.1300\n",
            "Epoch 425/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.4833 - val_loss: 21.8439\n",
            "Epoch 426/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.5148 - val_loss: 21.7397\n",
            "Epoch 427/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.4477 - val_loss: 21.9142\n",
            "Epoch 428/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.4332 - val_loss: 21.7795\n",
            "Epoch 429/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.4084 - val_loss: 21.7867\n",
            "Epoch 430/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.4164 - val_loss: 21.6678\n",
            "Epoch 431/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.3383 - val_loss: 21.4486\n",
            "Epoch 432/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.3749 - val_loss: 21.4662\n",
            "Epoch 433/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.2739 - val_loss: 21.2713\n",
            "Epoch 434/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9.2725 - val_loss: 21.4788\n",
            "Epoch 435/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.2189 - val_loss: 21.2168\n",
            "Epoch 436/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9.2173 - val_loss: 21.5710\n",
            "Epoch 437/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.1881 - val_loss: 21.3969\n",
            "Epoch 438/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.1796 - val_loss: 21.7777\n",
            "Epoch 439/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.1798 - val_loss: 21.5290\n",
            "Epoch 440/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.1522 - val_loss: 21.3590\n",
            "Epoch 441/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.1442 - val_loss: 21.4413\n",
            "Epoch 442/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.0757 - val_loss: 21.4870\n",
            "Epoch 443/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.0563 - val_loss: 21.4617\n",
            "Epoch 444/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9.0757 - val_loss: 21.1896\n",
            "Epoch 445/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 9.0036 - val_loss: 21.2314\n",
            "Epoch 446/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.0413 - val_loss: 21.2292\n",
            "Epoch 447/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 8.9967 - val_loss: 21.4859\n",
            "Epoch 448/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 8.9464 - val_loss: 20.9598\n",
            "Epoch 449/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.0033 - val_loss: 20.9536\n",
            "Epoch 450/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.9077 - val_loss: 21.2339\n",
            "Epoch 451/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.9583 - val_loss: 21.2240\n",
            "Epoch 452/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 8.8785 - val_loss: 20.9658\n",
            "Epoch 453/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.8658 - val_loss: 21.1444\n",
            "Epoch 454/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 8.8157 - val_loss: 21.0930\n",
            "Epoch 455/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.8069 - val_loss: 20.9694\n",
            "Epoch 456/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.7835 - val_loss: 21.0096\n",
            "Epoch 457/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.7887 - val_loss: 20.8721\n",
            "Epoch 458/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.7390 - val_loss: 20.6951\n",
            "Epoch 459/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.7315 - val_loss: 20.6830\n",
            "Epoch 460/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 8.6998 - val_loss: 20.6000\n",
            "Epoch 461/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 8.6700 - val_loss: 20.2091\n",
            "Epoch 462/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.6768 - val_loss: 20.5950\n",
            "Epoch 463/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.7807 - val_loss: 20.8415\n",
            "Epoch 464/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.6371 - val_loss: 20.4806\n",
            "Epoch 465/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.5922 - val_loss: 20.8035\n",
            "Epoch 466/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.6648 - val_loss: 20.7625\n",
            "Epoch 467/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.5937 - val_loss: 20.4860\n",
            "Epoch 468/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.5609 - val_loss: 20.3037\n",
            "Epoch 469/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.5598 - val_loss: 20.3936\n",
            "Epoch 470/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.5181 - val_loss: 20.0437\n",
            "Epoch 471/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.5526 - val_loss: 20.3113\n",
            "Epoch 472/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.5080 - val_loss: 20.3652\n",
            "Epoch 473/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.4454 - val_loss: 19.9903\n",
            "Epoch 474/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.4295 - val_loss: 20.0781\n",
            "Epoch 475/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.4447 - val_loss: 20.4583\n",
            "Epoch 476/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.3916 - val_loss: 20.3410\n",
            "Epoch 477/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.3770 - val_loss: 20.0678\n",
            "Epoch 478/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 8.3621 - val_loss: 19.9597\n",
            "Epoch 479/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.3487 - val_loss: 19.9532\n",
            "Epoch 480/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.3544 - val_loss: 20.0073\n",
            "Epoch 481/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.3164 - val_loss: 19.9322\n",
            "Epoch 482/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.3254 - val_loss: 19.7704\n",
            "Epoch 483/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.2797 - val_loss: 20.0250\n",
            "Epoch 484/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.2766 - val_loss: 20.1006\n",
            "Epoch 485/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.2630 - val_loss: 19.7895\n",
            "Epoch 486/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.2724 - val_loss: 20.2580\n",
            "Epoch 487/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.2259 - val_loss: 19.9883\n",
            "Epoch 488/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.2208 - val_loss: 19.5980\n",
            "Epoch 489/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.1937 - val_loss: 19.4988\n",
            "Epoch 490/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.1449 - val_loss: 19.9906\n",
            "Epoch 491/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.1621 - val_loss: 19.7673\n",
            "Epoch 492/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 8.1403 - val_loss: 19.8019\n",
            "Epoch 493/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 8.0796 - val_loss: 19.9447\n",
            "Epoch 494/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.1213 - val_loss: 19.8411\n",
            "Epoch 495/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 8.0543 - val_loss: 19.9371\n",
            "Epoch 496/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.0676 - val_loss: 19.6518\n",
            "Epoch 497/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.0539 - val_loss: 19.9103\n",
            "Epoch 498/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 8.0457 - val_loss: 19.6584\n",
            "Epoch 499/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 8.0031 - val_loss: 19.5469\n",
            "Epoch 500/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 8.0267 - val_loss: 19.7395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_learning_curve(history):\n",
        "  plt.plot(list(range(len(history['loss']))), history['loss'])\n",
        "  plt.plot(list(range(len(history['val_loss']))), history['val_loss'])\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.title(\"Learning Curve\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "zCuT8FoQp6Yy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_learning_curve(h.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "snp3WM11qIJf",
        "outputId": "82874781-ccc7-44a1-83e4-29f5619a852c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKsgOVoyqUe7",
        "outputId": "ff88a3cc-ed7c-4cdb-c606-e8b21db892aa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 13)                182       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 8)                 112       \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 5)                 45        \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 345\n",
            "Trainable params: 345\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "Yg04DfsWqdI2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "wtJkfjTdrKFe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = load_model('model.h5')\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HexhvviWrRns",
        "outputId": "f2347ef8-e28d-4d43-e6d2-10e62dc64bfd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 13)                182       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 8)                 112       \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 5)                 45        \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 345\n",
            "Trainable params: 345\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P = new_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laLLCo4wrVfw",
        "outputId": "d7c6635c-ea1b-4827-de58-e4e3687b3d19"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45K9AY3drnhZ",
        "outputId": "8da91271-b0c2-46f8-c7f4-acebf41e9c78"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[22.519562 ],\n",
              "       [25.180302 ],\n",
              "       [24.85315  ],\n",
              "       [11.738683 ],\n",
              "       [19.462189 ],\n",
              "       [19.51661  ],\n",
              "       [22.932804 ],\n",
              "       [21.212765 ],\n",
              "       [21.857704 ],\n",
              "       [16.621002 ],\n",
              "       [10.813156 ],\n",
              "       [12.486655 ],\n",
              "       [14.801397 ],\n",
              "       [11.320531 ],\n",
              "       [43.070827 ],\n",
              "       [35.641117 ],\n",
              "       [23.71316  ],\n",
              "       [38.77682  ],\n",
              "       [29.89711  ],\n",
              "       [22.891361 ],\n",
              "       [23.618183 ],\n",
              "       [20.942204 ],\n",
              "       [18.86805  ],\n",
              "       [26.880821 ],\n",
              "       [23.20298  ],\n",
              "       [16.334835 ],\n",
              "       [17.128117 ],\n",
              "       [15.979302 ],\n",
              "       [42.945282 ],\n",
              "       [18.399754 ],\n",
              "       [14.471624 ],\n",
              "       [16.73147  ],\n",
              "       [19.050259 ],\n",
              "       [20.60813  ],\n",
              "       [26.151512 ],\n",
              "       [19.080212 ],\n",
              "       [11.218561 ],\n",
              "       [30.851402 ],\n",
              "       [14.110193 ],\n",
              "       [12.791972 ],\n",
              "       [25.011906 ],\n",
              "       [22.4925   ],\n",
              "       [20.157448 ],\n",
              "       [14.9247675],\n",
              "       [20.491041 ],\n",
              "       [22.986774 ],\n",
              "       [20.44482  ],\n",
              "       [16.310219 ],\n",
              "       [15.442117 ],\n",
              "       [22.171936 ],\n",
              "       [14.282356 ],\n",
              "       [18.673595 ],\n",
              "       [22.514381 ],\n",
              "       [41.558826 ],\n",
              "       [14.466916 ],\n",
              "       [20.878633 ],\n",
              "       [20.109081 ],\n",
              "       [17.169792 ],\n",
              "       [11.388317 ],\n",
              "       [19.270613 ],\n",
              "       [18.727863 ],\n",
              "       [20.59042  ],\n",
              "       [36.146824 ],\n",
              "       [32.005352 ],\n",
              "       [15.43954  ],\n",
              "       [29.202282 ],\n",
              "       [15.76907  ],\n",
              "       [17.354015 ],\n",
              "       [13.338201 ],\n",
              "       [23.305336 ],\n",
              "       [20.225494 ],\n",
              "       [22.194115 ],\n",
              "       [24.99297  ],\n",
              "       [30.781345 ],\n",
              "       [27.484592 ],\n",
              "       [11.1762705],\n",
              "       [44.145588 ],\n",
              "       [22.45213  ],\n",
              "       [25.311787 ],\n",
              "       [18.889946 ],\n",
              "       [26.25417  ],\n",
              "       [17.043606 ],\n",
              "       [18.49247  ],\n",
              "       [44.385975 ],\n",
              "       [44.391933 ],\n",
              "       [23.218706 ],\n",
              "       [23.356232 ],\n",
              "       [13.66988  ],\n",
              "       [22.982834 ],\n",
              "       [14.928309 ],\n",
              "       [15.180138 ],\n",
              "       [12.142932 ],\n",
              "       [20.830519 ],\n",
              "       [31.431488 ],\n",
              "       [20.809608 ],\n",
              "       [19.769566 ],\n",
              "       [11.345553 ],\n",
              "       [22.656048 ],\n",
              "       [13.902233 ],\n",
              "       [17.871105 ],\n",
              "       [24.389965 ],\n",
              "       [19.281979 ],\n",
              "       [28.978233 ],\n",
              "       [21.751925 ],\n",
              "       [25.628696 ],\n",
              "       [21.209389 ],\n",
              "       [11.033455 ],\n",
              "       [19.162556 ],\n",
              "       [20.716747 ],\n",
              "       [25.906075 ],\n",
              "       [35.511906 ],\n",
              "       [12.356909 ],\n",
              "       [18.182247 ],\n",
              "       [19.17018  ],\n",
              "       [15.603564 ],\n",
              "       [21.024094 ],\n",
              "       [11.078388 ],\n",
              "       [18.300167 ],\n",
              "       [12.0592165],\n",
              "       [42.282883 ],\n",
              "       [30.345955 ],\n",
              "       [12.502507 ],\n",
              "       [20.124065 ],\n",
              "       [19.969063 ],\n",
              "       [22.123837 ],\n",
              "       [20.201073 ],\n",
              "       [39.329655 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rky0HI79rpv8",
        "outputId": "e7cdef5d-83c7-4835-9097-8c83a72e9c6b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 19.7395\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19.739484786987305"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}